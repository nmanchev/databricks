{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "711f4f56-fbb3-4648-ac39-00de72c5fd03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Pushing HuggingFace models to Databricks Unity Catalog\n",
    "\n",
    "A simple notebook to test loading and storing an arbitrary HuggingFace model into Unity Catalog.\n",
    "\n",
    "Run on a DBR 16.3 ML LTS cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "79490c22-0898-4f54-92ec-d6dbfb94554f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Test with a random HugginFace model. We use `microsoft/DialoGPT-small`\n",
    "\n",
    "First, we load the pipeline and make sure it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a81df96-9dca-412f-b6a8-7aeafe62e17d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the conversational pipeline\n",
    "chatbot = pipeline(\"text-generation\", model=\"microsoft/DialoGPT-small\")\n",
    "\n",
    "# Start a conversation\n",
    "response = chatbot(\"Hello, who are you?\")\n",
    "\n",
    "# Print the response\n",
    "print(\"Bot:\", response[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d5e8faf9-6754-4eb5-bb48-fc2278aad815",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "Next, let's register the model in Unity Catalog\n",
    "\n",
    "Fill in the TODO sections with details relevant to your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11fbf0a8-7744-48ad-8850-ce7bd85b463d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# TODO - add your Unity Catalog and schema here\n",
    "CATALOG = \"...\"\n",
    "SCHEMA = \"...\"\n",
    "MODEL_NAME = \"...\"\n",
    "\n",
    "\n",
    "fq_model_name = \".\".join([CATALOG, SCHEMA, MODEL_NAME])\n",
    "\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# Log the pipeline\n",
    "with mlflow.start_run():\n",
    "    model_info = mlflow.transformers.log_model(\n",
    "        transformers_model=chatbot,\n",
    "        artifact_path=\"chatbot\",\n",
    "        task=\"conversational\",\n",
    "        input_example=\"A clever and witty question\",\n",
    "        registered_model_name=fq_model_name\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a32dbcc7-f700-4fca-a6dc-73f1c96e00b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Finally, let's create a serving endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2d9400e-9db2-4ccd-a1d8-67fb64884d6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.deployments import get_deploy_client\n",
    "\n",
    "# Add your model version and endpoint name here\n",
    "MODEL_VERSION = 1\n",
    "ENDPOINT_NAME = \"...\"\n",
    "\n",
    "model_name_version = \"-\".join([MODEL_NAME, str(MODEL_VERSION)])\n",
    "\n",
    "client = get_deploy_client(\"databricks\")\n",
    "\n",
    "# Define the endpoint configuration\n",
    "endpoint_config = {\n",
    "    \"served_entities\": [\n",
    "        {\n",
    "            \"entity_name\": fq_model_name,  \n",
    "            \"entity_version\": MODEL_VERSION,  \n",
    "            \"workload_size\": \"Small\",  # Small, Medium, or Large\n",
    "            \"scale_to_zero_enabled\": True  # Set to False for production workloads\n",
    "        }\n",
    "    ],\n",
    "    \"traffic_config\": {\n",
    "        \"routes\": [\n",
    "            {\n",
    "                \"served_model_name\": model_name_version,\n",
    "                \"traffic_percentage\": 100  # Route all traffic to this model\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create the serving endpoint\n",
    "endpoint_name = ENDPOINT_NAME  \n",
    "endpoint = client.create_endpoint(name=endpoint_name, config=endpoint_config)\n",
    "\n",
    "print(f\"Serving endpoint created: {endpoint}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "HuggingFace UC DBR 16.3",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
