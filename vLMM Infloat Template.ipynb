{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e2c7d1a-63d1-4928-95f8-0bea1a89e1a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "%md\n",
    "# Intfloat/multilingual-e5-large-instruct Model Deployment\n",
    "\n",
    "## Prerequisites\n",
    "- Databricks workspace with appropriate permissions\n",
    "- Access to Hugging Face models\n",
    "- Sufficient GPU resources for model deployment\n",
    "\n",
    "## Cluster Configuration\n",
    "- Runtime: 16.3 ML (includes Apache Spark 3.5.2, GPU, Scala 2.12)\n",
    "- Node Type: Standard_NC40ads_H100_v5 [H100] (beta)\n",
    "- 320 GB Memory\n",
    "- 1 GPU\n",
    "- 40 Cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a59d4573-57ad-440e-8813-3964fb96c075",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Install Required Dependencies\n",
    "\n",
    "Installing necessary packages including:\n",
    "- OpenAI client\n",
    "- VLLM for efficient model serving\n",
    "- MLflow extensions for deployment\n",
    "- Transformers library with Qwen VL support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ede3f7b2-1fb6-4466-aa89-71aea2c2c7c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "PIP_REQUIREMENTS = (\n",
    "    \"openai vllm==0.8.5.post1 optree \"\n",
    "    \"git+https://github.com/huggingface/transformers accelerate  \"\n",
    "    \"mlflow==2.19.0 \"\n",
    "    \"git+https://github.com/stikkireddy/mlflow-extensions.git@vllm-embeddings-support \"\n",
    "    \"qwen-vl-utils \"\n",
    ")\n",
    "\n",
    "%pip install {PIP_REQUIREMENTS}\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd5f8118-ad1e-4666-99fd-26cb5b3957a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Configuration\n",
    "\n",
    "Set up the necessary configuration parameters for model deployment:\n",
    "- Catalog and schema for model registration\n",
    "- Model and endpoint names\n",
    "- Environment variables for VLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b3b0c68-90d7-4c22-903a-974d79ea8c7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "# Configuration parameters\n",
    "CATALOG = \"...\"\n",
    "SCHEMA = \"...\"\n",
    "MODEL_NAME = \"...\"\n",
    "ENDPOINT_NAME = \"...\"\n",
    "\n",
    "# Set environment variables for VLLM\n",
    "import os\n",
    "# os.environ['VLLM_WORKER_MULTIPROC_METHOD'] = 'spawn'\n",
    "# os.environ['VLLM_USE_V1'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a7d351e-7f85-4ee3-b1ee-5dc854024641",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "PIP_REQUIREMENTS = (\n",
    "    \"openai vllm==0.8.5.post1 optree \"\n",
    "    \"git+https://github.com/huggingface/transformers accelerate  \"\n",
    "    \"mlflow==2.19.0 \"\n",
    "    \"git+https://github.com/stikkireddy/mlflow-extensions.git@vllm-embeddings-support \"\n",
    "    \"qwen-vl-utils \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4fb9d41-321a-4d76-935e-abd07ae66642",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from mlflow_extensions.serving.engines import VLLMEngineProcess\n",
    "from mlflow_extensions.serving.engines.vllm_engine import VLLMEngineConfig\n",
    "from mlflow_extensions.databricks.deploy.ez_deploy import EzDeployConfig, ServingConfig, EzDeployVllmOpenCompat\n",
    "\n",
    "# Replace 'your_huggingface_token' with your actual Hugging Face token\n",
    "# login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fc03d71-d0c2-497c-8d31-341357c575a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the deployer with VLLM OpenAI compatibility layer\n",
    "deployer = EzDeployVllmOpenCompat(\n",
    "  config= EzDeployConfig(\n",
    "    # Specify the model name/path from Hugging Face\n",
    "    name=\"intfloat/multilingual-e5-large-instruct\",\n",
    "    # Use VLLM engine process for serving\n",
    "    engine_proc=VLLMEngineProcess,\n",
    "    engine_config=VLLMEngineConfig(\n",
    "          # Model identifier on Hugging Face\n",
    "          model=\"intfloat/multilingual-e5-large-instruct\",\n",
    "          # Maximum sequence length for input\n",
    "          max_model_len = 512,\n",
    "          # Maximum number of images/videos that can be processed\n",
    "          # VLLM specific configuration flags\n",
    "          vllm_command_flags={\n",
    "            # GPU memory utilization target (98%)\n",
    "            \"--gpu-memory-utilization\": .95,\n",
    "            \"--task\" : \"embedding\",\n",
    "          },\n",
    "),\n",
    "  serving_config=ServingConfig(\n",
    "      # Minimum memory required for model serving (in GB)\n",
    "      # Includes model weights, KV cache, overhead and intermediate states\n",
    "      minimum_memory_in_gb=60,\n",
    "  ),\n",
    "  # Use pip requirements defined earlier\n",
    "  pip_config_override = PIP_REQUIREMENTS.split(\" \")\n",
    "),\n",
    "  # Register model with fully qualified name in Unity Catalog\n",
    "  registered_model_name=f\"{CATALOG}.{SCHEMA}.{MODEL_NAME}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d81401ea-c356-4a55-a2b9-30feba4a5266",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Model Registration and Deployment\n",
    "\n",
    "Download and register the model in Unity Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d66e9e7a-d976-4152-83ef-cde2b8a480d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Download and register the model\n",
    "deployer.artifacts = deployer._config.download_artifacts(local_dir=\"/tmp/\") # this can be volume location as well\n",
    "deployer._downloaded = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9342a76f-fe66-43bd-b8e1-521952aed95a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "deployer.register() # Ignore error as this will fail in serverless as there are no GPU's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "555643a8-eeb2-4297-8457-8c93a8f36304",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Below is the code to deploy the endpoint to model serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e24f7b8-9bbf-42fc-9881-319912f8f079",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Model Deployment to Serving Endpoint\n",
    "\n",
    "Deploy the registered model to a serving endpoint. This will:\n",
    "1. Create a new serving endpoint with the specified name\n",
    "2. Load the model into memory\n",
    "3. Make it available for inference requests\n",
    "\n",
    "Note: `scale_to_zero=False` means the endpoint will maintain at least one instance running,\n",
    "which helps reduce cold start times but may incur higher costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c754ff3-e1ad-490c-8f0b-da93bbc3d7e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "deployer.deploy(ENDPOINT_NAME, scale_to_zero=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d658428d-81f2-4cfa-a806-9b0681d36a67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Process Management\n",
    "\n",
    "### Restarting Model Processes\n",
    "\n",
    "Sometimes you may need to restart the model processes, for example:\n",
    "- After making configuration changes\n",
    "- If the model becomes unresponsive\n",
    "- To free up GPU memory\n",
    "\n",
    "The following code will:\n",
    "1. Kill any existing VLLM processes\n",
    "2. Kill any Ray processes (used for distributed computing)\n",
    "3. Kill any multiprocessing processes\n",
    "\n",
    "Run this cell whenever you need to restart the model processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "969f0357-d103-40cc-a41b-c12550acec76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow_extensions.testing.helper import kill_processes_containing\n",
    "\n",
    "# Kill existing processes to free up resources\n",
    "kill_processes_containing(\"vllm\")  # Kill VLLM model serving processes\n",
    "kill_processes_containing(\"ray\")   # Kill Ray distributed computing processes\n",
    "kill_processes_containing(\"from multiprocessing\")  # Kill any multiprocessing processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2eb13470-a08c-4040-8949-3f338159b065",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Model Serving Setup\n",
    "\n",
    "Initialize the model for serving and set up the client for inference.\n",
    "This section will:\n",
    "1. Set up MLflow registry URI\n",
    "2. Fetch the latest model version\n",
    "3. Load the model for serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a83f1fe-41e4-4035-b709-4e4e7c22650d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Set up MLflow registry\n",
    "mlflow.set_registry_uri('databricks-uc')\n",
    "\n",
    "# Initialize MLflow client\n",
    "client = MlflowClient()\n",
    "\n",
    "# Get the latest model version\n",
    "model_name = f\"{CATALOG}.{SCHEMA}.{MODEL_NAME}\"\n",
    "latest_version = None\n",
    "\n",
    "# Iterate through versions to find the latest one\n",
    "for i in range(1, 10):\n",
    "    try:\n",
    "        client.get_model_version(model_name, i)\n",
    "    except:\n",
    "        latest_version = i - 1\n",
    "        break\n",
    "\n",
    "if latest_version is None:\n",
    "    raise Exception(\"Could not determine latest model version\")\n",
    "\n",
    "print(f\"Using latest model version: {latest_version}\")\n",
    "\n",
    "# Load the registered model\n",
    "model_uri = f\"models:/{model_name}/{latest_version}\"\n",
    "pyfunc_model = mlflow.pyfunc.load_model(model_uri)\n",
    "base_url = str(pyfunc_model.unwrap_python_model()._engine._server_http_client.base_url)\n",
    "\n",
    "print(\"Model serving base URL:\", base_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3886e4b4-6b85-46b6-a354-b60906be0e88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Inference Examples\n",
    "\n",
    "Demonstrate model inference capabilities with different types of inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9a0336c-3937-4b8a-a245-f8b7e6c1c290",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Text-only Inference\n",
    "\n",
    "Basic text completion example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78d70d0a-f504-42aa-954e-563563592db3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "serving_payload = {\"input\": [\"this is a new test\"]}\n",
    "\n",
    "response = pyfunc_model.predict(serving_payload)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "481ba533-404d-4269-955f-04aefe05ec91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": "HIGH"
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "vLMM Infloat Template",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
